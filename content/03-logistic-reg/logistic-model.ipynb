{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with the logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn import neighbors\n",
    "\n",
    "from statsmodels.formula.api import logit\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we will use the `Default` data set to demonstrate logistic regression for classification. The response variable is `default`, which takes on the value `Yes` if the customer defaults on their credit card payment and `No` if they do not. Run the code cell below to load the `Default` data as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://github.com/pykale/transparentML/raw/main/data/Default.csv\"\n",
    "df = pd.read_csv(data_url)\n",
    "\n",
    "# Note: factorize() returns two objects: a label array and an array with the unique values.\n",
    "# We are only interested in the first object.\n",
    "df[\"default2\"] = df.default.factorize()[0]\n",
    "df[\"student2\"] = df.student.factorize()[0]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An overview of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 5))\n",
    "gs = GridSpec(1, 4)\n",
    "ax1 = plt.subplot(gs[0, :-2])\n",
    "ax2 = plt.subplot(gs[0, -2])\n",
    "ax3 = plt.subplot(gs[0, -1])\n",
    "\n",
    "# Take a fraction of the samples where target value (default) is 'no'\n",
    "df_no = df[df.default2 == 0].sample(frac=0.15)\n",
    "# Take all samples  where target value is 'yes'\n",
    "df_yes = df[df.default2 == 1]\n",
    "#\n",
    "df_ = pd.concat((df_no, df_yes))\n",
    "\n",
    "ax1.scatter(\n",
    "    df_[df_.default == \"Yes\"].balance,\n",
    "    df_[df_.default == \"Yes\"].income,\n",
    "    s=40,\n",
    "    c=\"orange\",\n",
    "    marker=\"+\",\n",
    "    linewidths=1,\n",
    ")\n",
    "ax1.scatter(\n",
    "    df_[df_.default == \"No\"].balance,\n",
    "    df_[df_.default == \"No\"].income,\n",
    "    s=40,\n",
    "    marker=\"o\",\n",
    "    linewidths=1,\n",
    "    edgecolors=\"lightblue\",\n",
    "    facecolors=\"white\",\n",
    "    alpha=0.6,\n",
    ")\n",
    "#\n",
    "ax1.set_ylim(ymin=0)\n",
    "ax1.set_ylabel(\"Income\")\n",
    "ax1.set_xlim(xmin=-100)\n",
    "ax1.set_xlabel(\"Balance\")\n",
    "\n",
    "c_palette = {\"No\": \"lightblue\", \"Yes\": \"orange\"}\n",
    "sns.boxplot(data=df, y=\"balance\", x=\"default\", orient=\"v\", ax=ax2, palette=c_palette)\n",
    "sns.boxplot(data=df, y=\"income\", x=\"default\", orient=\"v\", ax=ax3, palette=c_palette)\n",
    "gs.tight_layout(plt.gcf())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression models the probability that `y` belongs to a particular category rather than modelling this response `y` directly. For the `Default` data, logistic regression models the probability of default. For example, the probability of default given balance can be written as\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(\\text{default} = \\text{Yes} \\mid \\text{balance}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.balance.values.reshape(-1, 1)\n",
    "y = df.default2\n",
    "\n",
    "# Create array of test data. Calculate the classification probability\n",
    "# and predicted classification.\n",
    "X_test = np.arange(df.balance.min(), df.balance.max()).reshape(-1, 1)\n",
    "\n",
    "clf = LogisticRegression(solver=\"newton-cg\")\n",
    "clf.fit(X_train, y)\n",
    "prob = clf.predict_proba(X_test)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Left plot\n",
    "sns.regplot(\n",
    "    x=df.balance,\n",
    "    y=df.default2,\n",
    "    order=1,\n",
    "    ci=None,\n",
    "    scatter_kws={\"color\": \"orange\"},\n",
    "    line_kws={\"color\": \"lightblue\", \"lw\": 2},\n",
    "    ax=ax1,\n",
    ")\n",
    "# Right plot\n",
    "ax2.scatter(X_train, y, color=\"orange\")\n",
    "ax2.plot(X_test, prob[:, 1], color=\"lightblue\")\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.hlines(\n",
    "        1,\n",
    "        xmin=ax.xaxis.get_data_interval()[0],\n",
    "        xmax=ax.xaxis.get_data_interval()[1],\n",
    "        linestyles=\"dashed\",\n",
    "        lw=1,\n",
    "    )\n",
    "    ax.hlines(\n",
    "        0,\n",
    "        xmin=ax.xaxis.get_data_interval()[0],\n",
    "        xmax=ax.xaxis.get_data_interval()[1],\n",
    "        linestyles=\"dashed\",\n",
    "        lw=1,\n",
    "    )\n",
    "    ax.set_ylabel(\"Probability of default\")\n",
    "    ax.set_xlabel(\"Balance\")\n",
    "    ax.set_yticks([0, 0.25, 0.5, 0.75, 1.0])\n",
    "    ax.set_xlim(xmin=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver=\"newton-cg\")\n",
    "X_train = df.balance.values.reshape(-1, 1)\n",
    "clf.fit(X_train, y)\n",
    "print(clf)\n",
    "print(\"classes: \", clf.classes_)\n",
    "print(\"coefficients: \", clf.coef_)\n",
    "print(\"intercept :\", clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = logit(\"default2 ~ balance\", df).fit()\n",
    "est.summary2().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = logit(\"default2 ~ student\", df).fit()\n",
    "est.summary2().tables[1]"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
