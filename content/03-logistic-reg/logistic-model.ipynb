{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with the logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In R, I exported the dataset from package 'ISLR' to an Excel file\n",
    "data_url = \"https://github.com/pykale/transparentML/raw/main/data/Default.xlsx\"\n",
    "df = pd.read_excel(data_url)\n",
    "\n",
    "# Note: factorize() returns two objects: a label array and an array with the unique values.\n",
    "# We are only interested in the first object.\n",
    "df[\"default2\"] = df.default.factorize()[0]\n",
    "df[\"student2\"] = df.student.factorize()[0]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An overview of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 5))\n",
    "gs = mpl.gridspec.GridSpec(1, 4)\n",
    "ax1 = plt.subplot(gs[0, :-2])\n",
    "ax2 = plt.subplot(gs[0, -2])\n",
    "ax3 = plt.subplot(gs[0, -1])\n",
    "\n",
    "# Take a fraction of the samples where target value (default) is 'no'\n",
    "df_no = df[df.default2 == 0].sample(frac=0.15)\n",
    "# Take all samples  where target value is 'yes'\n",
    "df_yes = df[df.default2 == 1]\n",
    "df_ = df_no.append(df_yes)\n",
    "\n",
    "ax1.scatter(\n",
    "    df_[df_.default == \"Yes\"].balance,\n",
    "    df_[df_.default == \"Yes\"].income,\n",
    "    s=40,\n",
    "    c=\"orange\",\n",
    "    marker=\"+\",\n",
    "    linewidths=1,\n",
    ")\n",
    "ax1.scatter(\n",
    "    df_[df_.default == \"No\"].balance,\n",
    "    df_[df_.default == \"No\"].income,\n",
    "    s=40,\n",
    "    marker=\"o\",\n",
    "    linewidths=\"1\",\n",
    "    edgecolors=\"lightblue\",\n",
    "    facecolors=\"white\",\n",
    "    alpha=0.6,\n",
    ")\n",
    "\n",
    "ax1.set_ylim(ymin=0)\n",
    "ax1.set_ylabel(\"Income\")\n",
    "ax1.set_xlim(xmin=-100)\n",
    "ax1.set_xlabel(\"Balance\")\n",
    "\n",
    "c_palette = {\"No\": \"lightblue\", \"Yes\": \"orange\"}\n",
    "sns.boxplot(\"default\", \"balance\", data=df, orient=\"v\", ax=ax2, palette=c_palette)\n",
    "sns.boxplot(\"default\", \"income\", data=df, orient=\"v\", ax=ax3, palette=c_palette)\n",
    "gs.tight_layout(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.balance.values.reshape(-1, 1)\n",
    "y = df.default2\n",
    "\n",
    "# Create array of test data. Calculate the classification probability\n",
    "# and predicted classification.\n",
    "X_test = np.arange(df.balance.min(), df.balance.max()).reshape(-1, 1)\n",
    "\n",
    "clf = skl_lm.LogisticRegression(solver=\"newton-cg\")\n",
    "clf.fit(X_train, y)\n",
    "prob = clf.predict_proba(X_test)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Left plot\n",
    "sns.regplot(\n",
    "    df.balance,\n",
    "    df.default2,\n",
    "    order=1,\n",
    "    ci=None,\n",
    "    scatter_kws={\"color\": \"orange\"},\n",
    "    line_kws={\"color\": \"lightblue\", \"lw\": 2},\n",
    "    ax=ax1,\n",
    ")\n",
    "# Right plot\n",
    "ax2.scatter(X_train, y, color=\"orange\")\n",
    "ax2.plot(X_test, prob[:, 1], color=\"lightblue\")\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.hlines(\n",
    "        1,\n",
    "        xmin=ax.xaxis.get_data_interval()[0],\n",
    "        xmax=ax.xaxis.get_data_interval()[1],\n",
    "        linestyles=\"dashed\",\n",
    "        lw=1,\n",
    "    )\n",
    "    ax.hlines(\n",
    "        0,\n",
    "        xmin=ax.xaxis.get_data_interval()[0],\n",
    "        xmax=ax.xaxis.get_data_interval()[1],\n",
    "        linestyles=\"dashed\",\n",
    "        lw=1,\n",
    "    )\n",
    "    ax.set_ylabel(\"Probability of default\")\n",
    "    ax.set_xlabel(\"Balance\")\n",
    "    ax.set_yticks([0, 0.25, 0.5, 0.75, 1.0])\n",
    "    ax.set_xlim(xmin=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = skl_lm.LogisticRegression(solver=\"newton-cg\")\n",
    "X_train = df.balance.values.reshape(-1, 1)\n",
    "clf.fit(X_train, y)\n",
    "print(clf)\n",
    "print(\"classes: \", clf.classes_)\n",
    "print(\"coefficients: \", clf.coef_)\n",
    "print(\"intercept :\", clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(df.balance)\n",
    "est = smf.Logit(y.ravel(), X_train).fit()\n",
    "est.summary2().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(df.student2)\n",
    "y = df.default2\n",
    "\n",
    "est = smf.Logit(y, X_train).fit()\n",
    "est.summary2().tables[1]"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
