{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalised linear models\n",
    "\n",
    "We use the [Bikeshare dataset](https://github.com/pykale/transparentML/blob/main/data/Bikeshare.csv) to illustrate generalised linear models (glm). The response is bikers, the number of hourly users of a bike sharing program in Washington, DC. This response value is neither qualitative nor quantitative: instead, it takes on non-negative integer values, or counts. We will consider predicting `bikers` using the covariates `mnth` (month of the year), `hr` (hour of the day, from 0 to 23), `workingday` (an indicator variable that equals 1 if it is neither a weekend nor a holiday), `temp` (the normalized temperature, in Celsius), and `weathersit` (a qualitative variable that takes on one of four possible values: clear; misty or cloudy; light rain or light snow; or heavy rain or heavy snow.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from statsmodels.formula.api import ols, poisson\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://github.com/pykale/transparentML/raw/main/data/Bikeshare.csv\"\n",
    "\n",
    "data_df = pd.read_csv(data_url, header=0, index_col=0)\n",
    "data_df[\"mnth\"] = data_df[\"mnth\"].astype(\"category\")\n",
    "data_df[\"hr\"] = data_df[\"hr\"].astype(\"category\")\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression on the `Bikeshare` data\n",
    "\n",
    "To begin, we consider predicting `bikers` using linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = ols(\"bikers ~ mnth + hr + temp + workingday + weathersit\", data_df).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, for example, that a progression of weather from clear to cloudy results in, on average, 12.89 fewer bikers per hour; however, if the weather progresses further to light rain or snow, then this further results in 53.60 fewer bikers per hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# months = [\"Jan\", \"Feb\", \"March\", \"April\", \"May\", \"June\", \"July\", \"Aug\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "months = [\n",
    "    \"Jan\",\n",
    "    \"Feb\",\n",
    "    \"March\",\n",
    "    \"May\",\n",
    "    \"June\",\n",
    "    \"July\",\n",
    "    \"Aug\",\n",
    "    \"Sept\",\n",
    "    \"Oct\",\n",
    "    \"Nov\",\n",
    "    \"Dec\",\n",
    "]\n",
    "coef_mnth = [est.params[\"mnth[T.%s]\" % _m] for _m in months]\n",
    "coef_hr = [est.params[\"hr[T.%d]\" % _h] for _h in range(1, 24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1.plot(months, coef_mnth, \"bo-\")\n",
    "ax1.set_xlabel(\"Month\")\n",
    "ax2.plot(np.arange(1, 24), coef_hr, \"bo-\")\n",
    "ax2.set_xlabel(\"Hour\")\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.set_ylabel(\"Coefficient\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figures display the coefficients associated with `mnth` and `hr`, respectively. We see that bike usage is highest in the spring and fall, and lowest during the winter months. Furthermore, bike usage is greatest around rush hour (9 AM and 6 PM), and lowest overnight. Thus, at first glance, fitting a linear regression model to the `Bikeshare` dataset seems to provide reasonable and intuitive results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson regression on the `Bikeshare` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = poisson(\"bikers ~ mnth + hr + temp + workingday + weathersit\", data_df).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_mnth = [est.params[\"mnth[T.%s]\" % _m] for _m in months]\n",
    "coef_hr = [est.params[\"hr[T.%d]\" % _h] for _h in range(1, 24)]\n",
    "\n",
    "# Create plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1.plot(months, coef_mnth, \"bo-\")\n",
    "ax1.set_xlabel(\"Month\")\n",
    "ax2.plot(np.arange(1, 24), coef_hr, \"bo-\")\n",
    "ax2.set_xlabel(\"Hour\")\n",
    "\n",
    "for ax in fig.axes:\n",
    "    #     ax.legend([\"student\", \"non-student\"], loc=2)\n",
    "    #     ax.set_xlabel(\"Income\")\n",
    "    ax.set_ylabel(\"Coefficient\")\n",
    "#     ax.set_ylim(ymax=1550)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized linear models\n",
    "\n",
    "Common characteristics of generalized linear models:\n",
    "\n",
    "1. Each approach uses predictors $ x_1, x_2, \\dots, x_D $ to predict a response $ y $. We assume that, conditional on $ x_1, x_2,\\dots, x_D $, $ y $ belongs to a certain family of distributions. For linear regression, we typically assume that $ y $ follows a Gaussian or normal distribution. For logistic regression, we assume that $y$ follows a Bernoulli distribution. Finally, for Poisson regression, we assume that $y$ follows a Poisson distribution.\n",
    "2. Each approach models the mean of $y$ as a function of the predictors. In linear regression, the mean of $y$ takes the form\n",
    "    $$\n",
    "    \\mathbb{E}(y|x_1, x_2, \\dots, x_D) = \\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_p x_D.\n",
    "    $$\n",
    "    In logistic regression, the mean of $y$ takes the form\n",
    "    $$\n",
    "    \\mathbb{E}(y|x_1, x_2, \\dots, x_D) = \\mathbb{P}(y=1|x_1, x_2, \\dots, x_D) = \\frac{e^{\\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_p x_D}}{1 + e^{\\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_p x_D}}.\n",
    "    $$\n",
    "    In Poisson regression, the mean of $y$ takes the form\n",
    "    $$\n",
    "    \\mu = e^{\\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_p x_D}.\n",
    "    $$\n",
    "\n",
    "The Gaussian, Bernoulli and Poisson distributions are all members of a wider class of distributions, known as the exponential family. Other well known members of this family are the exponential distribution, the Gamma distribution, and the negative binomial distribution. In general, we can perform a regression by modelling the response $y$ as coming from a particular member of the exponential family, and then transforming the mean of the response so that the transformed mean is a linear function of the predictors via (4.42). Any regression approach that follows this very general recipe is known as a generalized linear model (GLM). Thus, linear regression, logistic regression, and Poisson regression are three examples of GLMs. Other examples not covered here include _Gamma regression_ and _negative binomial regression_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "min 3 max 5\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
