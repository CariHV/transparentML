
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. Intro to Machine Learning &amp; Transparency &#8212; Transparent ML Intro</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Prerequisites" href="00-prerequisites.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/transparentml-logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Transparent ML Intro</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   Overview
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="00-prerequisites.html">
   Prerequisites
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Basics
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. Intro ML &amp; Transparency
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/01-ml-transparency.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/pykale/transparentML"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/pykale/transparentML/issues/new?title=Issue%20on%20page%20%2F01-ml-transparency.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/pykale/transparentML/edit/main/content/01-ml-transparency.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/pykale/transparentML/main?urlpath=tree/content/01-ml-transparency.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/pykale/transparentML/blob/main/content/01-ml-transparency.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-machine-learning">
   1.1. What is machine learning?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#human-learning">
     1.1.1. Human learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-definition-of-machine-learning">
     1.1.2. A definition of machine learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ai-machine-learning-and-deep-learning">
     1.1.3. AI, machine learning, and deep learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-and-problems">
   1.2. Data and problems
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#real-world-datasets-in-this-course">
     1.2.1. Real-world datasets in this course
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-problems">
     1.2.2. Machine learning problems
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercises">
     1.2.3. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning-systems">
   1.3. Machine learning systems
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#basic-notations">
     1.3.1. Basic notations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-ingredients">
     1.3.2. Machine learning ingredients
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-models">
     1.3.3. Machine learning models
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning-process">
   1.4. Machine learning process
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lifecycle-phases-for-design-development">
     1.4.1. Lifecycle phases for design &amp; development:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lifecycle-phases-for-system-deployment">
     1.4.2. Lifecycle phases for system deployment
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#execution-of-lifecycle-phases">
     1.4.3. Execution of lifecycle phases
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reproducibility-of-ml-systems">
     1.4.4. Reproducibility of ML systems
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning-transparency">
   1.5. Machine learning transparency
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-is-transparency-important">
     1.5.1. Why is transparency important?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-transparency">
     1.5.2. What is transparency?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#relevant-information">
     1.5.3. Relevant information
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#relevant-stakeholders">
     1.5.4. Relevant stakeholders
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reasons-for-accessing-information">
     1.5.5. Reasons for accessing information
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#trade-offs">
     1.5.6. Trade-offs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#system-transparency">
   1.6. System transparency
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-relevant-information">
     1.6.1. What relevant information?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-such-info">
     1.6.2. Why such info?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#system-performance">
       1.6.2.1. System performance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#system-compliance">
       1.6.2.2. System compliance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#competent-use-human-oversight">
       1.6.2.3. Competent use &amp; human oversight
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#providing-explanations">
       1.6.2.4. Providing explanations
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#responsiveness">
       1.6.2.5. Responsiveness
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#social-and-economic-impact">
       1.6.2.6. Social and economic impact
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-obtain-communicate-such-info">
     1.6.3. How to obtain &amp; communicate such info?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#obtaining-system-logic-information">
       1.6.3.1. Obtaining system logic information
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#machine-learning-interpretability">
       1.6.3.2. Machine learning interpretability
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#communicating-system-logic-information">
       1.6.3.3. Communicating system logic information
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#process-transparency">
   1.7. Process transparency
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     1.7.1. What relevant information?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     1.7.2. Why such info?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-manage-such-info">
     1.7.3. How to manage such info?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#k-nearest-neighbors-knn-classification">
   1.8. K-Nearest Neighbors (KNN) classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     1.8.1. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quiz">
   1.9. Quiz
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   1.10. Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references-and-further-reading">
   1.11. References and further reading
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Intro to Machine Learning & Transparency</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-machine-learning">
   1.1. What is machine learning?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#human-learning">
     1.1.1. Human learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-definition-of-machine-learning">
     1.1.2. A definition of machine learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ai-machine-learning-and-deep-learning">
     1.1.3. AI, machine learning, and deep learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-and-problems">
   1.2. Data and problems
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#real-world-datasets-in-this-course">
     1.2.1. Real-world datasets in this course
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-problems">
     1.2.2. Machine learning problems
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercises">
     1.2.3. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning-systems">
   1.3. Machine learning systems
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#basic-notations">
     1.3.1. Basic notations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-ingredients">
     1.3.2. Machine learning ingredients
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#machine-learning-models">
     1.3.3. Machine learning models
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning-process">
   1.4. Machine learning process
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lifecycle-phases-for-design-development">
     1.4.1. Lifecycle phases for design &amp; development:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lifecycle-phases-for-system-deployment">
     1.4.2. Lifecycle phases for system deployment
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#execution-of-lifecycle-phases">
     1.4.3. Execution of lifecycle phases
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reproducibility-of-ml-systems">
     1.4.4. Reproducibility of ML systems
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning-transparency">
   1.5. Machine learning transparency
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-is-transparency-important">
     1.5.1. Why is transparency important?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-transparency">
     1.5.2. What is transparency?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#relevant-information">
     1.5.3. Relevant information
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#relevant-stakeholders">
     1.5.4. Relevant stakeholders
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reasons-for-accessing-information">
     1.5.5. Reasons for accessing information
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#trade-offs">
     1.5.6. Trade-offs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#system-transparency">
   1.6. System transparency
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-relevant-information">
     1.6.1. What relevant information?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-such-info">
     1.6.2. Why such info?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#system-performance">
       1.6.2.1. System performance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#system-compliance">
       1.6.2.2. System compliance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#competent-use-human-oversight">
       1.6.2.3. Competent use &amp; human oversight
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#providing-explanations">
       1.6.2.4. Providing explanations
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#responsiveness">
       1.6.2.5. Responsiveness
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#social-and-economic-impact">
       1.6.2.6. Social and economic impact
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-obtain-communicate-such-info">
     1.6.3. How to obtain &amp; communicate such info?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#obtaining-system-logic-information">
       1.6.3.1. Obtaining system logic information
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#machine-learning-interpretability">
       1.6.3.2. Machine learning interpretability
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#communicating-system-logic-information">
       1.6.3.3. Communicating system logic information
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#process-transparency">
   1.7. Process transparency
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     1.7.1. What relevant information?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     1.7.2. Why such info?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-manage-such-info">
     1.7.3. How to manage such info?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#k-nearest-neighbors-knn-classification">
   1.8. K-Nearest Neighbors (KNN) classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     1.8.1. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quiz">
   1.9. Quiz
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   1.10. Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references-and-further-reading">
   1.11. References and further reading
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="intro-to-machine-learning-transparency">
<h1><span class="section-number">1. </span>Intro to Machine Learning &amp; Transparency<a class="headerlink" href="#intro-to-machine-learning-transparency" title="Permalink to this headline">¶</a></h1>
<!-- **Question**: What is machine learning and what is AI transparency? -->
<div class="admonition-objectives admonition">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Understand real-world datasets used in this course</p></li>
<li><p>Understand components of typical machine learning systems</p></li>
<li><p>Understand steps in typical machine learning processes</p></li>
<li><p>Understand AI transparency definition &amp; taxonomy</p></li>
</ul>
</div>
<p><strong>Expected time to complete</strong>: 4 hours</p>
<p>In this chapter, we will learn about the components of typical machine learning systems and steps in typical machine learning processes. We will also learn about the definition and taxonomy of AI transparency. We will start with the real-world datasets used in this course to see how machine learning can be used in real-world.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you do not have prior knowledge/experience with linear algebra, Python programming, and probability and statistics, please go through <a class="reference internal" href="00-prerequisites.html"><span class="doc">Prerequisites</span></a> before starting this course.</p>
</div>
<div class="section" id="what-is-machine-learning">
<h2><span class="section-number">1.1. </span>What is machine learning?<a class="headerlink" href="#what-is-machine-learning" title="Permalink to this headline">¶</a></h2>
<div class="section" id="human-learning">
<h3><span class="section-number">1.1.1. </span>Human learning<a class="headerlink" href="#human-learning" title="Permalink to this headline">¶</a></h3>
<p>Learning is familiar to humans (and animals), as a continuous process that starts from birth and continues throughout life. A human child (and adult) learns new things, acquire new skills, and improve existing skills to survive and thrive in the surrounding world. A child’s brain and senses perceive the facts of their surroundings to gradually learn the hidden patterns of life that help the child to craft logical rules to identify learned patterns and predict future events.</p>
<p>Learning is a process of acquiring new knowledge, skills, and behaviors. Learning can be divided into two categories: <strong>acquisition</strong> and <strong>performance</strong>. Acquisition is the process of acquiring new knowledge, skills, and behaviors. Performance is the process of using the acquired knowledge, skills, and behaviors to achieve a goal. Learning can be defined as a change in behavior or knowledge that results from experience. We learn from our experiences and we learn from others. For example, we learn to walk by watching others walk, we learn to speak by listening to others speak, we learn to drive by watching others drive, and we learn to cook by watching others cook.</p>
<p>You may have already known, since you are here, that machine can also learn, from their experiences, and from others. That is the subject of this course.</p>
</div>
<div class="section" id="a-definition-of-machine-learning">
<h3><span class="section-number">1.1.2. </span>A definition of machine learning<a class="headerlink" href="#a-definition-of-machine-learning" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Machine learning learns a model from data.</p>
</div></blockquote>
<p>Machine learning takes <strong>data</strong> as <strong>input</strong> to learn a <strong>model</strong>, a mathematical representation of the data. This learning process is called the <strong>training</strong> phase and the data used in training is called the <strong>training data</strong>. After training, the learned model can take new data, the <strong>test data</strong>, as input to generate <strong>output</strong> for making predictions on the test data or for exploring/explaining the test data, which is the <strong>test</strong> phase.</p>
<p>The above definition is the one we will use in this course for clarity, loosely inspired by how the human brain learns certain things based on the data it perceives from the outside world. From this definition, we can see machine learning as a set of <strong>software</strong> tools for <strong>modelling</strong> and <strong>understanding</strong> complex <strong>datasets</strong>. You may find various definitions of machine learning elsewhere. For example, machine learning, from a systems perspective, is defined as the creation of automated systems that can learn hidden patterns from data to aid in making intelligent decisions.</p>
</div>
<div class="section" id="ai-machine-learning-and-deep-learning">
<h3><span class="section-number">1.1.3. </span>AI, machine learning, and deep learning<a class="headerlink" href="#ai-machine-learning-and-deep-learning" title="Permalink to this headline">¶</a></h3>
<p>Besides machine learning (ML), you may have also heard about artificial intelligence (AI), deep learning, and data science. Some use these terms interchangeably, but they are not the same, as shown in the figure below.</p>
<div class="figure align-default" id="fig-ai-ml-ds">
<a class="reference internal image-reference" href="https://github.com/microsoft/ML-For-Beginners/raw/main/1-Introduction/1-intro-to-ML/images/ai-ml-ds.png"><img alt="https://github.com/microsoft/ML-For-Beginners/raw/main/1-Introduction/1-intro-to-ML/images/ai-ml-ds.png" src="https://github.com/microsoft/ML-For-Beginners/raw/main/1-Introduction/1-intro-to-ML/images/ai-ml-ds.png" style="height: 250px;" /></a>
<p class="caption"><span class="caption-number">Fig. 1.1 </span><span class="caption-text">The relationships between AI, ML, deep learning, and data science, by <a class="reference external" href="https://twitter.com/jenlooper">Jen Looper</a> adapted from <a class="reference external" href="https://softwareengineering.stackexchange.com/questions/366996/distinction-between-ai-ml-neural-networks-deep-learning-and-data-mining">stackexchange</a> (can be redrawn by us later).</span><a class="headerlink" href="#fig-ai-ml-ds" title="Permalink to this image">¶</a></p>
</div>
<p><strong>AI</strong> is a broad field of study that aims to create intelligent machines that can perform tasks that normally require human intelligence. There are multiple ways to achieve AI, and machine learning is one of them. As defined above, machine learning is a subfield of AI that machines acquire their experiences from data, in the form of a mathematical model. There are multiple ways of machine learning, and deep learning is one of them. <strong>Deep learning</strong> is a subfield of machine learning that uses deep (i.e. many layers) neural networks to learn from data. <strong>Data science</strong> is a broad field of study that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from data, not necessarily in the form of a mathematical model as machine learning does.</p>
</div>
</div>
<div class="section" id="data-and-problems">
<h2><span class="section-number">1.2. </span>Data and problems<a class="headerlink" href="#data-and-problems" title="Permalink to this headline">¶</a></h2>
<p>This section introduces the real-world datasets used in this course. We will also learn about the machine learning problems that can be solved using these datasets. Before we talk about the datasets, let’s first define what machine learning is.</p>
<div class="section" id="real-world-datasets-in-this-course">
<h3><span class="section-number">1.2.1. </span>Real-world datasets in this course<a class="headerlink" href="#real-world-datasets-in-this-course" title="Permalink to this headline">¶</a></h3>
<p>In this course, we will use real-world datasets to introduce machine learning from the perspective of AI transparency. We will use the following datasets from the textbook. You can click on the name of the dataset to see the actual data.</p>
<table class="colwidths-auto table" id="datasets-table">
<caption><span class="caption-number">Table 1.1 </span><span class="caption-text">Datasets used in this course, from the textbook (to refine)</span><a class="headerlink" href="#datasets-table" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Data provided</p></th>
<th class="head"><p>Machine learning problem</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Auto.csv">Auto</a></p></td>
<td><p>Gas mileage, horsepower, and other information for cars.</p></td>
<td><p>Predict gas mileage for a car.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Bikeshare.csv">Bikeshare</a></p></td>
<td><p>Hourly usage of a bike sharing program in Washington, DC.</p></td>
<td><p>Predict the number of bikes rented per hour.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Boston.csv">Boston</a></p></td>
<td><p>Housing values and other information about Boston census tracts.</p></td>
<td><p>Predict the median value of a house.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/BrainCancer.csv">BrainCancer</a></p></td>
<td><p>Survival times for patients diagnosed with brain cancer.</p></td>
<td><p>Predict the survival time for a patient.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Caravan.csv">Caravan</a></p></td>
<td><p>Information about individuals offered caravan insurance.</p></td>
<td><p>Predict whether an individual will buy caravan insurance.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Carseats.csv">Carseats</a></p></td>
<td><p>Information about car seat sales in 400 stores.</p></td>
<td><p>Predict the sales of a car seat.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/College.csv">College</a></p></td>
<td><p>Demographic characteristics, tuition, and more for USA colleges.</p></td>
<td><p>Predict the number of applications received by a college.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Credit.csv">Credit</a></p></td>
<td><p>Information about credit card debt for 10,000 customers.</p></td>
<td><p>Predict the amount of credit card debt for a customer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Default.csv">Default</a></p></td>
<td><p>Customer default records for a credit card company.</p></td>
<td><p>Predict whether a customer will default on a credit card payment.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Fund.csv">Fund</a></p></td>
<td><p>Returns of 2,000 hedge fund managers over 50 months.</p></td>
<td><p>Predict the returns of a hedge fund manager.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Hitters.csv">Hitters</a></p></td>
<td><p>Records and salaries for baseball players.</p></td>
<td><p>Predict the salary of a baseball player.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Khan.json">Khan</a></p></td>
<td><p>Gene expression measurements for four cancer types.</p></td>
<td><p>Predict the cancer type for a patient.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://en.wikipedia.org/wiki/NCI-60">NCI60</a></p></td>
<td><p>Gene expression measurements for 64 cancer cell lines.</p></td>
<td><p>Find clusters or groups among the cell lines for personalised treatment.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/OJ.csv">OJ</a></p></td>
<td><p>Sales information for Citrus Hill and Minute Maid orange juice.</p></td>
<td><p>Predict the sales of orange juice.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Portfolio.csv">Portfolio</a></p></td>
<td><p>Past values of financial assets, for use in portfolio allocation.</p></td>
<td><p>Predict the value of a financial asset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Publication.csv">Publication</a></p></td>
<td><p>Time to publication for 244 clinical trials.</p></td>
<td><p>Predict the time to publication for a clinical trial.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Smarket.csv">Smarket</a></p></td>
<td><p>Daily percentage returns for S&amp;P 500 over a 5-year period.</p></td>
<td><p>Predict whether the stock index with increase or decrease.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/USArrests.csv">USArrests</a></p></td>
<td><p>Crime statistics per 100,000 residents in 50 states of USA.</p></td>
<td><p>Predict the crime rate in a state.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Wage.csv">Wage</a></p></td>
<td><p>Income survey data for men in central Atlantic region of USA.</p></td>
<td><p>Predict the income of men</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Weekly.csv">Weekly</a></p></td>
<td><p>1,089 weekly stock market returns for 21 years.</p></td>
<td><p>Predict the stock market return in a week</p></td>
</tr>
</tbody>
</table>
<!-- * - [NYSE](https://github.com/pykale/transparentML/blob/main/data/.csv)  
  - Returns, volatility, and volume for the New York Stock Exchange.
  - Predict the returns of a stock. -->
<p>The above datasets show the diverse range of problems that machine learning can solve, which shows only the tip of the iceberg actually. Applications of machine learning are everywhere, from healthcare to finance, from manufacturing to agriculture, from transportation to education, and so on. The datasets used in this course are from the textbook, which is a good starting point for learning about machine learning. However, you can also find many other datasets online, such as <a class="reference external" href="https://www.kaggle.com/datasets">Kaggle</a>, <a class="reference external" href="https://archive.ics.uci.edu/ml/index.php">UCI Machine Learning Repository</a>, <a class="reference external" href="https://www.openml.org/">OpenML</a>, <a class="reference external" href="https://datasetsearch.research.google.com/">Google Dataset Search</a>, and so on.</p>
<p>Next, let us learn about the machine learning problems in their typical definitions.</p>
</div>
<div class="section" id="machine-learning-problems">
<h3><span class="section-number">1.2.2. </span>Machine learning problems<a class="headerlink" href="#machine-learning-problems" title="Permalink to this headline">¶</a></h3>
<p>Machine learning problems can be broadly classified into two categories: <strong>supervised learning</strong> and <strong>unsupervised learning</strong>. In supervised learning, the data is labelled, and the goal is to predict or estimate the label for new data. In unsupervised learning, the data is not labelled, and the goal is to find patterns, such as relationships or structures, in the data. Machine learning models can generate two types of outputs: discrete and continuous. Discrete outputs are categorical, such as the class of an image. Continuous outputs are numerical, such as the price of a house.</p>
<p>Thus, supervised learning can be further divided into classification and regression. In <strong>classification</strong>, the output is a discrete (e.g. categorical or <em>qualitative</em>) value, such as a category or a class. In <strong>regression</strong>, the output is a continuous (e.g. <em>quantitative</em>) value, such as a number or a probability. Unsupervised learning can be further divided into clustering and dimensionality reduction. In <strong>clustering</strong>, the goal is to find groups of similar data points so the output is a discrete value, such as a cluster index. In <strong>dimensionality reduction</strong>, the goal is to find a lower-dimensional representation of the data so the output is of continuous values, such as a vector.</p>
<p>The following table shows the different types of machine learning problems in the context of the above definitions.</p>
<table class="colwidths-auto table" id="mlproblems-table">
<caption><span class="caption-number">Table 1.2 </span><span class="caption-text">Supervised and unsupervised machine learning</span><a class="headerlink" href="#mlproblems-table" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Machine Learning</p></th>
<th class="head"><p>Supervised</p></th>
<th class="head"><p>Unsupervised</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Discrete output</strong></p></td>
<td><p>Classification</p></td>
<td><p>Clustering</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Continuous output</strong></p></td>
<td><p>Regression</p></td>
<td><p>Dimensionality reduction</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="exercises">
<h3><span class="section-number">1.2.3. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h3>
<ol>
<li><p>Choose three or more datasets of your interest from <a class="reference internal" href="#datasets-table"><span class="std std-numref">Table 1.1</span></a>. Click on the name of each chosen dataset to explore and get a sense of the data. You may not be able to get a beautiful view or a view at all for those larger ones. Write down the possible machine learning problems using terminology in <a class="reference internal" href="#mlproblems-table"><span class="std std-numref">Table 1.2</span></a> that can be solved using each of your chosen dataset. Click below for a sample answer.</p>
<div class="toggle docutils container">
<p>Sample answer: to be completed.</p>
</div>
</li>
<li><p>To be completed</p>
<div class="toggle docutils container">
<p>Sample answer: to be completed.</p>
</div>
</li>
</ol>
</div>
</div>
<div class="section" id="machine-learning-systems">
<h2><span class="section-number">1.3. </span>Machine learning systems<a class="headerlink" href="#machine-learning-systems" title="Permalink to this headline">¶</a></h2>
<div class="section" id="basic-notations">
<h3><span class="section-number">1.3.1. </span>Basic notations<a class="headerlink" href="#basic-notations" title="Permalink to this headline">¶</a></h3>
<p>We use notations slightly different from those in the textbook to reduce the cognitive load (hopefully). We use <span class="math notranslate nohighlight">\(N\)</span> to represent the number of <strong>samples</strong>, i.e. distinct data points or observations. We use <span class="math notranslate nohighlight">\(D\)</span> to represent the number of <strong>features</strong>, i.e. distinct variables or attributes that are available for learning a model,
also known as the <strong>dimensionality</strong>. We use <span class="math notranslate nohighlight">\(C\)</span> to represent the number of <strong>classes</strong>, i.e. distinct categories or labels. We use <span class="math notranslate nohighlight">\(\mathbf{x}_n\)</span> to represent the <span class="math notranslate nohighlight">\(n\)</span>-th sample, where <span class="math notranslate nohighlight">\(n = 1, 2, \ldots, N\)</span>. We use <span class="math notranslate nohighlight">\(x_{nd}\)</span> to represent the <span class="math notranslate nohighlight">\(d\)</span>-th feature of the <span class="math notranslate nohighlight">\(n\)</span>-th sample, where <span class="math notranslate nohighlight">\(d = 1, 2, \ldots, D\)</span>. We use <span class="math notranslate nohighlight">\(y_n\)</span> to represent the label of the <span class="math notranslate nohighlight">\(n\)</span>-th sample, where <span class="math notranslate nohighlight">\(y_n \in \{1, 2, \ldots, C\}\)</span>. We use <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> to represent the <strong>feature matrix</strong>, also know as the <strong>data matrix</strong>, where <span class="math notranslate nohighlight">\(\mathbf{X} = [\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_N]\)</span>. We use <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> to represent the label vector, where <span class="math notranslate nohighlight">\(\mathbf{y} = [y_1, y_2, \ldots, y_N]^\top\)</span>. We use <span class="math notranslate nohighlight">\(\mathbf{W}\)</span> to represent the <strong>weight matrix</strong>, where <span class="math notranslate nohighlight">\(\mathbf{W} = [\mathbf{w}_1, \mathbf{w}_2, \ldots, \mathbf{w}_C]\)</span>. We use <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> to represent the <strong>bias vector</strong>, where <span class="math notranslate nohighlight">\(\mathbf{b} = [b_1, b_2, \ldots, b_C]^\top\)</span>. We use <span class="math notranslate nohighlight">\(\mathbf{z}_n\)</span> to represent the linear combination of the <span class="math notranslate nohighlight">\(n\)</span>-th sample, where <span class="math notranslate nohighlight">\(\mathbf{z}_n = \mathbf{W} \mathbf{x}_n + \mathbf{b}\)</span>.</p>
 <!-- We use $\mathbf{a}_n$ to represent the activation of the $n$-th sample, where $\mathbf{a}_n = \sigma(\mathbf{z}_n)$. We use $\mathbf{Z}$ to represent the linear combination matrix, where $\mathbf{Z} = \{\mathbf{z}_1, \mathbf{z}_2, \ldots, \mathbf{z}_N\}$. We use $\mathbf{A}$ to represent the activation matrix, where $\mathbf{A} = \{\mathbf{a}_1, \mathbf{a}_2, \ldots, \mathbf{a}_N\}$. We use $\mathbf{Z}^T$ to represent the transpose of the linear combination matrix, where $\mathbf{Z}^T = \{\mathbf{z}_1^T, \mathbf{z}_2^T, \ldots, \mathbf{z}_N^T\}$. We use $\mathbf{A}^T$ to represent the transpose of the activation matrix, where $\mathbf{A}^T = \{\mathbf{a}_1^T, \mathbf{a}_2^T, \ldots, \mathbf{a}_N^T\}$. -->
</div>
<div class="section" id="machine-learning-ingredients">
<h3><span class="section-number">1.3.2. </span>Machine learning ingredients<a class="headerlink" href="#machine-learning-ingredients" title="Permalink to this headline">¶</a></h3>
<p>Machine learning systems are composed of three main ingredients: <strong>data</strong>, <strong>model</strong>, and <strong>loss function</strong>. The data is the input to the machine learning system. The model is the core of the machine learning system. The loss function is the output of the machine learning system. The following figure shows the three ingredients of a machine learning system.</p>
<p>A typical machine learning system is composed of the following ingredients:</p>
<ul class="simple">
<li><p><strong>Data/sample</strong>: a data point or observation <span class="math notranslate nohighlight">\(\mathbf{x}_n\)</span>, with <span class="math notranslate nohighlight">\(n = 1, 2, \ldots, N\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the total number of samples.</p></li>
<li><p><strong>Feature</strong>: each sample vector <span class="math notranslate nohighlight">\(\mathbf{x}_n\)</span> has <span class="math notranslate nohighlight">\(D\)</span> features as its representation, i.e. <span class="math notranslate nohighlight">\(D\)</span> variables or attributes that are available for learning a model.</p></li>
<li><p><strong>Prediction</strong>: each sample will have a prediction <span class="math notranslate nohighlight">\(\hat{y}_n\)</span> as its output.</p></li>
<li><p><strong>Label</strong>: only in supervised learning, each sample will have a label <span class="math notranslate nohighlight">\(y_n\)</span> as its ground truth. In classification, <span class="math notranslate nohighlight">\(y_n \in \{1, 2, \ldots, C\}\)</span>, where <span class="math notranslate nohighlight">\(C\)</span> is the total number of classes.</p></li>
<li><p><strong>Labeled dataset</strong>: a set of <span class="math notranslate nohighlight">\(N\)</span> tuples of the form <span class="math notranslate nohighlight">\((\mathbf{x}_n, y_n)\)</span>, where <span class="math notranslate nohighlight">\(n = 1, 2, \ldots, N\)</span>.</p></li>
<li><p><strong>Unlabeled dataset</strong>: a set of <span class="math notranslate nohighlight">\(N\)</span> samples <span class="math notranslate nohighlight">\(\mathbf{x}_n\)</span>, where <span class="math notranslate nohighlight">\(n = 1, 2, \ldots, N\)</span>.</p></li>
<li><p><strong>Model</strong>: a function <span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span> (the <strong>objective function</strong>) that maps a sample <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> to an output <span class="math notranslate nohighlight">\(\hat{y}\)</span>. This is the <em>focus</em> of machine learning. The objective of machine learning is to estimate a good model <span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span>. In classification, <span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span> maps a sample <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> to a class label <span class="math notranslate nohighlight">\(\hat{y} \in \{1, 2, \ldots, C\}\)</span>. In regression, <span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span> maps a sample <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> to a real number <span class="math notranslate nohighlight">\(\hat{y}\)</span>. In clustering, <span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span> maps a sample <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> to a cluster label <span class="math notranslate nohighlight">\(\hat{y} \in \{1, 2, \ldots, C\}\)</span>. In dimensionality reduction, <span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span> maps a sample <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> to a low-dimensional vector <span class="math notranslate nohighlight">\(\hat{\mathbf{y}}\)</span>.</p>
<ul>
<li><p><strong>Hyperparameters</strong>: the high-level parameters of a model that typically need to be <em>specified</em> before learning a model. These hyperparameters will determine the model structure/architecture. For example, the number of layers, the number of neurons in each layer, the activation function, the loss function, the optimizer, etc.</p></li>
<li><p><strong>Parameters</strong>: the model parameters are the specific realisation of a model to be <em>learned</em> during training, such as the weights and biases <span class="math notranslate nohighlight">\(\mathbf{W}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span>. In machine learning, it is common to denote all parameters as <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Loss function</strong>: a function <span class="math notranslate nohighlight">\(L(y, \hat{y})\)</span> (also known as <strong>error function</strong>) that measures the difference between the predicted output <span class="math notranslate nohighlight">\(\hat{y}\)</span> and the true or desired output <span class="math notranslate nohighlight">\(y\)</span> in supervised learning, or a function <span class="math notranslate nohighlight">\(L(y)\)</span> that measures some desired property (or properties) of the output in unsupervised learning. In classification, <span class="math notranslate nohighlight">\(L(y, \hat{y})\)</span> measures the difference between the predicted class label <span class="math notranslate nohighlight">\(\hat{y}\)</span> and the true class label <span class="math notranslate nohighlight">\(y\)</span>. In regression, <span class="math notranslate nohighlight">\(L(y, \hat{y})\)</span> measures the difference between the predicted real number <span class="math notranslate nohighlight">\(\hat{y}\)</span> and the true real number <span class="math notranslate nohighlight">\(y\)</span>. In clustering, <span class="math notranslate nohighlight">\(L(y)\)</span> typically measures the coherence and separation of clusters. In dimensionality reduction, <span class="math notranslate nohighlight">\(L(y)\)</span> typically measures the preservation of information in the input <span class="math notranslate nohighlight">\(\{\mathbf{x}_n\}\)</span>.</p>
<ul>
<li><p><strong>Evaluation metric/measure</strong>: an evaluation (or error) metric (or measure) is needed for a loss function <span class="math notranslate nohighlight">\(L(y, \hat{y})\)</span> or <span class="math notranslate nohighlight">\(\hat{y}\)</span> to be useful. For example, in classification, the evaluation metric is typically the accuracy, which is a function of the predicted label <span class="math notranslate nohighlight">\(\hat{y}\)</span> and the true label <span class="math notranslate nohighlight">\(y\)</span>.</p></li>
</ul>
</li>
<li><p><strong>learning/optimization algorithm</strong>: an algorithm that finds the best model <span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span> by minimizing the loss function <span class="math notranslate nohighlight">\(L(y, \hat{y})\)</span> or <span class="math notranslate nohighlight">\(\hat{y}\)</span>. Nowadays, the optimization algorithms are typically available in libraries (software packages) and do not need to be implemented by the user. The optimization algorithms are typically iterative algorithms that iteratively update the model parameters to minimize the loss function. The optimization algorithms are typically <em>black boxes</em> to the user. The user only needs to specify the loss function <span class="math notranslate nohighlight">\(L(y, \hat{y})\)</span> or <span class="math notranslate nohighlight">\(\hat{y}\)</span> and the optimization algorithm will find the best model <span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span>.</p></li>
</ul>
</div>
<div class="section" id="machine-learning-models">
<h3><span class="section-number">1.3.3. </span>Machine learning models<a class="headerlink" href="#machine-learning-models" title="Permalink to this headline">¶</a></h3>
<p>This course focuses on machine learning models (or methods) that are most widely used in practice, while NOT aiming to be exhaustive in covering all the models. The following table shows the machine learning models that we will cover in this course.</p>
<table class="colwidths-auto table" id="mlmethods-table">
<caption><span class="caption-number">Table 1.3 </span><span class="caption-text">Machine learning models/methods </span><a class="headerlink" href="#mlmethods-table" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Example</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Linear regression</strong></p></td>
<td><p>A linear model for regression.</p></td>
<td><p>Predicting the price of a house.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Logistic regression</strong></p></td>
<td><p>A linear model for classification.</p></td>
<td><p>Predicting whether a customer will default on a credit card payment.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Support vector machine</strong></p></td>
<td><p>A non-linear model for classification.</p></td>
<td><p>Predicting whether a customer will default on a credit card payment.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Decision tree</strong></p></td>
<td><p>A non-linear model for classification and regression.</p></td>
<td><p>Predicting whether a customer will default on a credit card payment.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Random forest</strong></p></td>
<td><p>An ensemble of decision trees for classification and regression.</p></td>
<td><p>Predicting whether a customer will default on a credit card payment.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Neural network</strong></p></td>
<td><p>A non-linear model for classification and regression.</p></td>
<td><p>Predicting whether a customer will default on a credit card payment.</p></td>
</tr>
<tr class="row-even"><td><p><strong>K-means</strong></p></td>
<td><p>A clustering algorithm.</p></td>
<td><p>Finding groups of similar customers.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Principal component analysis</strong></p></td>
<td><p>A dimensionality reduction algorithm.</p></td>
<td><p>Finding the most important features of a dataset.</p></td>
</tr>
</tbody>
</table>
<p>No single model will perform well in all possible scenarios. Therefore, it is important to understand the assumptions and trade-offs of each model so that you can choose the right model for a given problem.</p>
</div>
</div>
<div class="section" id="machine-learning-process">
<h2><span class="section-number">1.4. </span>Machine learning process<a class="headerlink" href="#machine-learning-process" title="Permalink to this headline">¶</a></h2>
<p>Machine learning process can be described in terms of lifecycle phases. The phases of An ML system’s lifecycle are a number of analytically distinct activities throughout the stages of system design, development, and deployment. There is no universally agreed breakdown of lifecycle phases for ML systems. However, the following illustrative typology is suitable for a range of contexts and intersects with prominent lifecycle frameworks. Some of the activities below only apply to certain phases of ML systems.</p>
<div class="section" id="lifecycle-phases-for-design-development">
<h3><span class="section-number">1.4.1. </span>Lifecycle phases for design &amp; development:<a class="headerlink" href="#lifecycle-phases-for-design-development" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><strong>Business case and problem definition</strong>: Establishing the need for the ML system and the tasks it is meant to perform.</p></li>
<li><p><strong>System requirements specification</strong>: Translating the problem definition into technical design and performance requirements.</p></li>
<li><p><strong>Data acquisition and preparation</strong>: Where relevant, acquiring any data that may be needed to build the system, checking its suitability, and preparing it for use, e.g. via data pre-processing and/or data augmentation.</p></li>
<li><p><strong>Building</strong>: Creating a system that meets the design requirements previously specified. In the case of ML projects, this involves choosing between ML methods, developing and evaluating candidate models, and selecting the best performing model.</p></li>
<li><p><strong>Validation and verification</strong>: Verifying, on an on-going basis, that the system meets the relevant design and performance requirements. Depending on the nature of the system, assessment can rely on empirical testing or formal verification.66</p></li>
</ul>
</div>
<div class="section" id="lifecycle-phases-for-system-deployment">
<h3><span class="section-number">1.4.2. </span>Lifecycle phases for system deployment<a class="headerlink" href="#lifecycle-phases-for-system-deployment" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><strong>Integration</strong>: Preparing the ML system for operation by integrating it into the relevant real-world (e.g. business) environment. This can involve technical aspects of integration with other systems or technology infrastructure. It also includes the introduction of users to the operation of the system, the delivery of user training, and other relevant aspects of organisational change management.</p></li>
<li><p><strong>Operation</strong>: Using the ML system to perform the real-world (e.g. business) tasks for which it was intended.</p></li>
<li><p><strong>Monitoring and evaluation</strong>: Observing and recording system behaviour in order to assess system performance and compliance during operation, including any procedures of periodic re-validation.</p></li>
<li><p><strong>Updating/system retirement</strong>: Making changes to the ML system as needed, for example to improve performance or prevent performance deterioration. In the context of supervised ML models, such changes take the form of retraining the model based on new training data. Successful updating is followed by another iteration of lifecycle steps outlined above.</p></li>
</ul>
</div>
<div class="section" id="execution-of-lifecycle-phases">
<h3><span class="section-number">1.4.3. </span>Execution of lifecycle phases<a class="headerlink" href="#execution-of-lifecycle-phases" title="Permalink to this headline">¶</a></h3>
<p>The lifecycle phases capture activities that are conceptually distinct, but do not necessarily occur in succession. During an ML system’s design and development, for example, agile processes can involve iterative cycles and adjustments across the different phases outlined above. When it comes to deployment, operation and monitoring/evaluation typically occur in parallel. Moreover, in the case of adaptive systems, updating can occur continually during operation.</p>
<p>The volumes of data needed for ML systems and the complexity of technology supply chains mean that different activities across lifecycle phases are not always performed by actors within the same organisation. In contexts that involve third-party data providers, outsourcing different aspects of system design and development, or reliance on off-the-shelf tools, certain activities will be carried out by actors outside of the firm using the system.</p>
<p>Indeed, some of these activities might not be carried out by human actors, but by ML systems: recent innovations make it possible to automate large sections of an ML system’s development. However, in any of these cases, the structure of lifecycle phases remains unaffected by this, as the fundamental steps in designing, developing, and deploying an ML system stay the same.</p>
</div>
<div class="section" id="reproducibility-of-ml-systems">
<h3><span class="section-number">1.4.4. </span>Reproducibility of ML systems<a class="headerlink" href="#reproducibility-of-ml-systems" title="Permalink to this headline">¶</a></h3>
<p>Maybe to add later.</p>
</div>
</div>
<div class="section" id="machine-learning-transparency">
<h2><span class="section-number">1.5. </span>Machine learning transparency<a class="headerlink" href="#machine-learning-transparency" title="Permalink to this headline">¶</a></h2>
<p>Transparency is a fundamental AI ethics principle key to <em>responsible</em> AI innovation <span id="id1">[<a class="reference internal" href="index.html#id7" title="Florian Ostmann and Cosmina Dorobantu. AI in financial services. Alan Turing Institute. doi, 2021. https://www.turing.ac.uk/sites/default/files/2021-06/ati_ai_in_financial_services_lores.pdf.">Ostmann and Dorobantu, 2021</a>]</span>. It plays a crucial role in the development of ML systems, as well as in the evaluation of their performance and the <em>trust</em> that people place in them. We follow the definition and framework of transparency in <span id="id2">[<a class="reference internal" href="index.html#id7" title="Florian Ostmann and Cosmina Dorobantu. AI in financial services. Alan Turing Institute. doi, 2021. https://www.turing.ac.uk/sites/default/files/2021-06/ati_ai_in_financial_services_lores.pdf.">Ostmann and Dorobantu, 2021</a>]</span> in this course.</p>
<div class="section" id="why-is-transparency-important">
<h3><span class="section-number">1.5.1. </span>Why is transparency important?<a class="headerlink" href="#why-is-transparency-important" title="Permalink to this headline">¶</a></h3>
<p>For ML systems to be trustworthy and to be used responsibly, it is vital to ensure that they are transparent, i.e. stakeholders have <em>access to information</em> relevant to them. Addressing concerns of AI and preventing potential harms of AI requires information being available to individuals involved in designing an ML system, developing it, deploying it, and using it, as well as to the general public, regulators, and other stakeholders for them to understand decisions made by the system, trust it, and hold it accountable. Different stakeholders are likely to have different information needs.</p>
<p>Transparency and accountability are closely related and reinforce each other. Accountability mechanisms depend on the
availability of information about an ML system and accountability is key motivation for transparency.
Transparency also acts as an enabler to other ML/AI ethics principles including fairness, sustainability, and safety.</p>
</div>
<div class="section" id="what-is-transparency">
<h3><span class="section-number">1.5.2. </span>What is transparency?<a class="headerlink" href="#what-is-transparency" title="Permalink to this headline">¶</a></h3>
<p>ML transparency relates to disclosing information about ML systems, and it can be understood as relevant stakeholders having access to relevant information about a given ML system. Transparency involves gathering and sharing information about an ML system’s logic (i.e. <em>explainability</em>) and how it was designed, developed, and deployed.</p>
<p>The three key questions to ask when considering transparency are:</p>
<ul class="simple">
<li><p><strong>What</strong> types of information are relevant?</p></li>
<li><p><strong>Who</strong> are the relevant stakeholders?</p></li>
<li><p><strong>Why</strong> are stakeholders interested in information about an ML system?</p></li>
</ul>
<p>Transparency is a <em>property</em> of the system, and it is <em>not</em> a property of the information itself. Transparency is a <em>relative</em> concept, and it is <em>not</em> an absolute concept. Transparency is <em>context-dependent</em> and it is <em>not</em> a fixed property of the system. For example, a system transparent to a doctor (data scientist) does not mean the system is transparent to a patient (customer). External stakeholders (e.g. regulators, the general public) may have different information needs than internal stakeholders (e.g. data scientists, developers, and engineers).</p>
</div>
<div class="section" id="relevant-information">
<h3><span class="section-number">1.5.3. </span>Relevant information<a class="headerlink" href="#relevant-information" title="Permalink to this headline">¶</a></h3>
<p>There are two broad categories of information considered relevant for transparency:</p>
<ul class="simple">
<li><p><strong>System logic information</strong>: Information that relates to the operational logic of a given ML system, i.e. information about the system’s ‘inner workings’. Examples include information about the input features that a system relies on or information about the relationship between the system’s inputs and outputs.</p></li>
<li><p><strong>Process information</strong>: Information that relates to the processes surrounding the ML system’s design, development, and deployment. Examples include information about data management practices, assessments of system performance, quality assurance (including of data) and governance arrangements, or the training of system users.</p></li>
</ul>
<p>Respectively, the above categories of information define two forms of transparency:</p>
<ul class="simple">
<li><p><strong>System transparency</strong>: Stakeholders having access to system logic information</p></li>
<li><p><strong>Process transparency</strong>: Stakeholders having access to process information</p></li>
</ul>
<p>In this course, we will study machine learning systems from the perspectives of these two forms of transparency.</p>
</div>
<div class="section" id="relevant-stakeholders">
<h3><span class="section-number">1.5.4. </span>Relevant stakeholders<a class="headerlink" href="#relevant-stakeholders" title="Permalink to this headline">¶</a></h3>
<p>The information that is relevant to a given stakeholder depends on the stakeholder’s role and the context. For example, a data scientist may need to know the details of the data collection process, while a data subject may need to know how their data is used. We can split those who may have an interest in system or process transparency into two categories:</p>
<ul class="simple">
<li><p><strong>Internal stakeholders</strong>: Those individuals who are involved in the design, development, and procurement of the ML system. Examples include data scientists, developers, and engineers. They also include individuals who make decisions about its deployment, operate the system, manage external communications, or perform corporate governance and oversight functions. Examples include members of development or procurement teams, risk and compliance teams, audit teams, senior management, company boards, operational teams using the ML system, and customer service teams.</p></li>
<li><p><strong>External stakeholders</strong>: Those individuals who are external to the organisation employing the ML system that have a significant relationship with the organisation deploying the system or may be affected by the ML system’s use. They are not involved in the design, development, procurement, and deployment of the ML system. Examples include regulators, customers, shareholders, academics, and the general public.</p></li>
</ul>
<p>Based on these two categories of stakeholders, we can make a second distinction in mapping out different types of transparency:</p>
<ul class="simple">
<li><p><strong>Internal transparency</strong>: Information being accessible to internal stakeholders</p></li>
<li><p><strong>External transparency</strong>: Information being accessible to external stakeholders</p></li>
</ul>
<p>This second distinction intersects with the first one, between system and process transparency.
System logic information or process information can be accessible to internal stakeholders,
external stakeholders, or both. The resulting four-fold transparency typology is summarised
in <a class="reference internal" href="#fig6-ai-transparency"><span class="std std-numref">Fig. 1.2</span></a> below.</p>
<div class="figure align-default" id="fig6-ai-transparency">
<img alt="_images/fig6-ai-transparency.png" src="_images/fig6-ai-transparency.png" />
<p class="caption"><span class="caption-number">Fig. 1.2 </span><span class="caption-text">AI transparency typology <span id="id3">[<a class="reference internal" href="index.html#id7" title="Florian Ostmann and Cosmina Dorobantu. AI in financial services. Alan Turing Institute. doi, 2021. https://www.turing.ac.uk/sites/default/files/2021-06/ati_ai_in_financial_services_lores.pdf.">Ostmann and Dorobantu, 2021</a>]</span> (maybe redraw later).</span><a class="headerlink" href="#fig6-ai-transparency" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="reasons-for-accessing-information">
<h3><span class="section-number">1.5.5. </span>Reasons for accessing information<a class="headerlink" href="#reasons-for-accessing-information" title="Permalink to this headline">¶</a></h3>
<p>As mentioned above, transparency is a <em>relative</em> concept. Not all types of information about an ML system will be equally important to all types of stakeholders. The reasons that underpin stakeholders’ interests in information about a given system (i.e. their ‘transparency interests’) are important in determining the types of information they may seek access to. When these reasons differ between stakeholders, the definition of what constitutes relevant information can change. For example, customers faced with an ML system used to make credit eligibility decisions may wish to understand the impact of, say, a 3% pay raise on their credit eligibility. The answer to this question can involve types of information that may not be relevant to the transparency interests, say, of regulators, which may be motivated by the goal of understanding
different aspects of system performance and compliance.</p>
<p>Stakeholders’ transparency interests can differ even when their reasons for seeking information are the same. For example, a risk and compliance officer may seek information about an ML system for the same reasons and look for answers to the same questions as a different internal stakeholder (eg a customer service representative) or an external stakeholder (eg a member of the public). Each of these stakeholders, however, might expect different levels of detail.</p>
<p>Figure <a class="reference internal" href="#fig7-ai-transparency"><span class="std std-numref">Fig. 1.3</span></a>7 summarises the three key questions of AI transparency so far.</p>
<div class="figure align-default" id="fig7-ai-transparency">
<img alt="_images/fig7-ai-transparency.png" src="_images/fig7-ai-transparency.png" />
<p class="caption"><span class="caption-number">Fig. 1.3 </span><span class="caption-text">Summary of the three key questions of transparency <span id="id4">[<a class="reference internal" href="index.html#id7" title="Florian Ostmann and Cosmina Dorobantu. AI in financial services. Alan Turing Institute. doi, 2021. https://www.turing.ac.uk/sites/default/files/2021-06/ati_ai_in_financial_services_lores.pdf.">Ostmann and Dorobantu, 2021</a>]</span> (maybe redraw later).</span><a class="headerlink" href="#fig7-ai-transparency" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="trade-offs">
<h3><span class="section-number">1.5.6. </span>Trade-offs<a class="headerlink" href="#trade-offs" title="Permalink to this headline">¶</a></h3>
<p>There can be reasons for not making some types of information about ML systems accessible to certain stakeholders. Such
reasons often play a prominent role in discussions about the disclosure of information to external stakeholders in particular. The applicability of such countervailing reasons is context dependent. In particular, these reasons, where relevant, do not speak against the disclosure of system logic and process information in a wholesale manner. Instead, they typically apply to the disclosure of specific types of information (e.g. specific aspects of system logic information rather than all types of system logic information) to specific types of stakeholders (e.g. customers rather than all external stakeholders), for specific types of use cases.</p>
<p>In addition, disclosing information that is irrelevant or excessively detailed in response to stakeholders’ questions may generate undue distrust. Avoiding ‘information overload’ is one possible reason against the disclosure of some types of information to certain stakeholders.</p>
<p>Three other potential reasons are worth noting:</p>
<ul class="simple">
<li><p><strong>Preventing system manipulation or ‘gaming’</strong>: In some cases, firms employing ML systems may seek to protect certain aspects of information to prevent the subversion of these systems. In the case of fraud detection systems, for instance, preventing adversarial actors from finding ways to evade detection can speak against disclosing information about system logic or the data used to customers. Yet, this countervailing reason does not necessarily apply to the disclosure of the same information to regulators, or the disclosure of other types of information to customers.</p></li>
<li><p><strong>Protecting commercially sensitive information</strong>: Certain types of information may be considered commercially sensitive by the firm employing an ML system or by third-party providers involved in the system’s development. For example, an investment management firm that relies on proprietary ML systems to identify profitable investment opportunities has an interest to protect the competitive advantage enabled by these systems. Similarly, third-party providers may want to protect the IP contained in their products. As such, firms may be reluctant to disclose information that is central to their commercial success. Once again, however, this reason typically only applies to specific types of information (eg details of a system’s logic or proprietary source code) and their disclosure to certain stakeholders.</p></li>
<li><p><strong>Protecting personal data</strong>: Certain forms of information disclosure can conflict with firms’ obligation to protect personal data. This includes, most obviously, the direct sharing of personal data – be it data used in the development or the operation of ML systems – in ways that violate data protection legislation. In addition, where ML systems are trained with personal data, it may be possible to infer protected personal information through, for example, model inversion or membership inference attacks. While concerns about such attacks only apply in limited circumstances, they can speak against the disclosure of certain aspects of system logic information to stakeholders.</p></li>
</ul>
<p>The applicability and implications of transparency trade-offs depend on context and vary between use cases. Regardless of the applicability of different countervailing reasons, large segments of the information that is of interest to stakeholders will remain unaffected.</p>
</div>
</div>
<div class="section" id="system-transparency">
<h2><span class="section-number">1.6. </span>System transparency<a class="headerlink" href="#system-transparency" title="Permalink to this headline">¶</a></h2>
<p>We will now focus on system transparency, i.e. the transparency of the system logic information. We aim to answer three questions:</p>
<ul class="simple">
<li><p>What types of information fall under the category of system transparency.</p></li>
<li><p>Why different stakeholders can be interested in them.</p></li>
<li><p>How such information can be obtained and communicated.</p></li>
</ul>
<p>Figure <a class="reference internal" href="#fig8-ai-transparency"><span class="std std-numref">Fig. 1.4</span></a> summarises system transparency in the three key questions above.</p>
<div class="figure align-default" id="fig8-ai-transparency">
<img alt="_images/fig8-ai-transparency.png" src="_images/fig8-ai-transparency.png" />
<p class="caption"><span class="caption-number">Fig. 1.4 </span><span class="caption-text">The what, why, and how of system transparency <span id="id5">[<a class="reference internal" href="index.html#id7" title="Florian Ostmann and Cosmina Dorobantu. AI in financial services. Alan Turing Institute. doi, 2021. https://www.turing.ac.uk/sites/default/files/2021-06/ati_ai_in_financial_services_lores.pdf.">Ostmann and Dorobantu, 2021</a>]</span> (maybe redraw later).</span><a class="headerlink" href="#fig8-ai-transparency" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="what-relevant-information">
<h3><span class="section-number">1.6.1. </span>What relevant information?<a class="headerlink" href="#what-relevant-information" title="Permalink to this headline">¶</a></h3>
<p>System transparency refers to access to information about the operational logic of a system. The most transparent systems are simple systems where system logic information can be inferred purely from a system’s formal
representation. Three types of information are considered relevant for system transparency:</p>
<blockquote>
<div><p>(1) The input variables that a given system relies on: what are the types of information that the system uses in operation?</p>
<p>(2) The way in which the system transforms inputs into outputs: what is the relationship between input variables and system results?</p>
<p>(3) The conditions under which the system would produce a certain output: for what values of the input variables would the system return a specific value of interest?</p>
</div></blockquote>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p>Let us know see illustrate how these three types of information can be inferred from the formal expression of a
simple system below, a linear model calculates a person’s credit score <span class="math notranslate nohighlight">\(y\)</span> (the output variable) as a function of their weekly income <span class="math notranslate nohighlight">\(x\)</span> (the input variable):</p>
<div class="math notranslate nohighlight">
\[y = 200 + 0.5x\]</div>
<p>This simple equation provides answers to all three questions outlined above:</p>
<ul class="simple">
<li><p>the model relies on a single input variable, namely weekly income <span class="math notranslate nohighlight">\(x\)</span>;</p></li>
<li><p>the model transforms the input variable into a credit score <span class="math notranslate nohighlight">\(y\)</span> (output) by multiplying it by a coefficient of 0.5 and adding a constant of 200;</p></li>
<li><p>in order for the model to yield an output value (credit score) of 600 (for example), the value
of weekly income <span class="math notranslate nohighlight">\(x\)</span> would need to be £800.</p></li>
</ul>
<p>Given that it is possible to infer these three types of information from its formal expression,
this simple model is <strong>fully transparent</strong>. Since the input variable <span class="math notranslate nohighlight">\(x\)</span> is an easily understandable real-world property,  this model is also <strong>full interpretable</strong>.</p>
</div>
<p>Many of the models that financial services firms use meet the definition of <em>interpretable models</em>. Their interpretation may require a higher level of mathematical knowledge, but their structure makes it possible to infer answers to the three questions above based on a <em>formal model expression</em>. The increases in model complexity enabled by ML methods can entail
a decrease in or loss of model interpretability. It will generally be possible to identify the input variables that ML models rely on (information in category (1) above). Yet, model complexity can make it difficult to understand – from a formal expression of the model – how inputs are transformed into outputs (information in category (2)) or the conditions under which the model yields a specific output (information in category (3)).</p>
<p>Decreases in interpretability can take two forms. First, as model complexity increases, interpreting models requires greater technical skills. This possibility of opacity due to non-expertise shows that interpretability is a relative concept. Whether an ML system is considered interpretable can depend on the level of technical expertise of those trying to understand it. Second, model complexity can take forms that make ML systems inscrutable, affecting their interpretability regardless of expertise. In such cases, experts may still be able to give partial answers to the question of how the model transforms inputs into outputs from a formal representation of it – for example, by providing a high-level description of the model’s structure. Yet, these partial answers fall far short of the complete understanding that can be gained from the formal expression of the simple linear model above.</p>
<p>The lack of interpretability of certain types of models does not necessarily mean that adequate forms of system logic information are unobtainable for these ML systems. Instead of obtaining information from the formal expression of models, system logic information can also be obtained indirectly, by using auxiliary strategies and tools, such as <em>explainability methods</em>.  However, these explainability methods cannot fully compensate for the information that can be obtained from interpretable systems.</p>
</div>
<div class="section" id="why-such-info">
<h3><span class="section-number">1.6.2. </span>Why such info?<a class="headerlink" href="#why-such-info" title="Permalink to this headline">¶</a></h3>
<p>Access to system logic information can serve to address relevant concerns (e.g. ensuring trustworthiness and responsible use) as well as to provide assurance about possible concerns (e.g. demonstrating trustworthiness and responsible use), as shown in.</p>
<div class="figure align-default" id="fig9-ai-transparency">
<img alt="_images/fig9-ai-transparency.png" src="_images/fig9-ai-transparency.png" />
<p class="caption"><span class="caption-number">Fig. 1.5 </span><span class="caption-text">Areas of concern related to system transparency <span id="id6">[<a class="reference internal" href="index.html#id7" title="Florian Ostmann and Cosmina Dorobantu. AI in financial services. Alan Turing Institute. doi, 2021. https://www.turing.ac.uk/sites/default/files/2021-06/ati_ai_in_financial_services_lores.pdf.">Ostmann and Dorobantu, 2021</a>]</span> (maybe redraw later).</span><a class="headerlink" href="#fig9-ai-transparency" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="system-performance">
<h4><span class="section-number">1.6.2.1. </span>System performance<a class="headerlink" href="#system-performance" title="Permalink to this headline">¶</a></h4>
<p>System logic information can be vital to understanding and improving the effectiveness, reliability, and robustness of ML systems. Where testing during system development reveals shortcomings, the analysis of input-output relationships can help identify possible improvements. Knowledge of input-output relationships can also be crucial when assessing the extent of possible performance issues that may arise during deployment. Stakeholders that may be interested in system logic information for these reasons include those involved in or making decisions about the development and use of ML systems as well as those seeking assurance about an ML system’s performance (including evaluation).</p>
</div>
<div class="section" id="system-compliance">
<h4><span class="section-number">1.6.2.2. </span>System compliance<a class="headerlink" href="#system-compliance" title="Permalink to this headline">¶</a></h4>
<p>Knowledge of the input variables that a system relies on and other aspects of system logic can be crucial to ensuring compliance with legal and regulatory standards and rules. For example, an understanding of system logic can be critical to avoiding unlawful discrimination; ensuring the adequacy in risk management; assessing the risks; or avoiding the unlawful
processing of personal data. As in the case of system performance, stakeholders that may be interested in system logic information for these reasons include those involved in or making decisions about the development and use of ML systems as well as those seeking assurance about system compliance.</p>
</div>
<div class="section" id="competent-use-human-oversight">
<h4><span class="section-number">1.6.2.3. </span>Competent use &amp; human oversight<a class="headerlink" href="#competent-use-human-oversight" title="Permalink to this headline">¶</a></h4>
<p>System users may need access to system logic information to ensure competent use. For example, knowledge of the input variables that a system relies on can be necessary to ensure that factors already accounted for in system outputs are not accounted for more than once (and therefore distort results) within a given decision process as a whole. Similarly, internal stakeholders in charge of oversight arrangements may need an understanding of system logic to determine what kind of oversight is required and to anticipate situations that call for intervention.</p>
</div>
<div class="section" id="providing-explanations">
<h4><span class="section-number">1.6.2.4. </span>Providing explanations<a class="headerlink" href="#providing-explanations" title="Permalink to this headline">¶</a></h4>
<p>System logic information can be at the core of explanations sought by
decision recipients. For instance, it can provide assurance that decisions are taken in non-arbitrary
and methodologically sound ways. In contexts such as credit or insurance underwriting, for
example, access to system logic information can also be important in order for decision recipients
to understand the effect that their behaviour may have on the decisions they receive.</p>
</div>
<div class="section" id="responsiveness">
<h4><span class="section-number">1.6.2.5. </span>Responsiveness<a class="headerlink" href="#responsiveness" title="Permalink to this headline">¶</a></h4>
<p>Customer service representatives, for example, may need to understand which
input variables a system relies on, how the system transforms inputs into outputs, or under what
conditions a system would yield certain results to be able to respond to customer queries.</p>
</div>
<div class="section" id="social-and-economic-impact">
<h4><span class="section-number">1.6.2.6. </span>Social and economic impact<a class="headerlink" href="#social-and-economic-impact" title="Permalink to this headline">¶</a></h4>
<p>System logic information can be essential to assessing potential
social and economic impacts or providing assurance in relation to concerns about such impacts.
For example, knowledge of the input variables used and the relationship between inputs and
outputs can be relevant to understanding whether the system relies on inferences whose use
may be considered ethically objectionable. Regulators, academics, or indeed wider civil society
stakeholders may have an interest in system logic information in order to assess social and
economic implications.</p>
</div>
</div>
<div class="section" id="how-to-obtain-communicate-such-info">
<h3><span class="section-number">1.6.3. </span>How to obtain &amp; communicate such info?<a class="headerlink" href="#how-to-obtain-communicate-such-info" title="Permalink to this headline">¶</a></h3>
<p>We now discuss how to obtain system logic information and how to communicate it to
relevant stakeholders.</p>
<div class="section" id="obtaining-system-logic-information">
<h4><span class="section-number">1.6.3.1. </span>Obtaining system logic information<a class="headerlink" href="#obtaining-system-logic-information" title="Permalink to this headline">¶</a></h4>
<p>There are two methodological paths to obtaining information about an ML system’s input-output
relationships and conditions under which it produces certain outputs:</p>
<ul class="simple">
<li><p>Direct interpretation: Where complexity allows, relevant information can be obtained by analysing
a formal representation of the system (as illustrated by the <a class="reference external" href="#what-relevant-information">example of the simple linear model</a>). This will be possible for many ML systems covered in this course, including those that are linear or non-linear but have a relatively simple structure. However, it will not be possible for all ML systems, including those that are non-linear and have a complex structure.</p></li>
<li><p>Indirect analysis using explainability methods: Various auxiliary methods can help shed light
on system logic. Many of these methods are perturbation-based – relying on the analysis of
changes in system outputs in response to changes in input values – and can be used without
access to a formal representation of the system. This is out of the scope of this course and hence will <em>NOT</em> be covered.</p></li>
</ul>
</div>
<div class="section" id="machine-learning-interpretability">
<h4><span class="section-number">1.6.3.2. </span>Machine learning interpretability<a class="headerlink" href="#machine-learning-interpretability" title="Permalink to this headline">¶</a></h4>
<p>In general, linear models allow for a more interpretable (but less flexible) model, while non-linear models allow for a more flexible (but less interpretable) model.</p>
<p>A trade-off between model flexibility and interpretability is shown in the figure below.</p>
<div class="figure align-default" id="fig-trade-off-interpretable-flexible">
<a class="reference internal image-reference" href="_images/fig2_7.png"><img alt="_images/fig2_7.png" src="_images/fig2_7.png" style="height: 300px;" /></a>
<p class="caption"><span class="caption-number">Fig. 1.6 </span><span class="caption-text">A trade-off between model flexibility and interpretability <span id="id7">[<a class="reference internal" href="index.html#id6" title="Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. An Introduction to Statistical Learning. Springer, 2021. https://www.statlearning.com/.">James <em>et al.</em>, 2021</a>]</span>.</span><a class="headerlink" href="#fig-trade-off-interpretable-flexible" title="Permalink to this image">¶</a></p>
</div>
<p>The decision to limit model complexity for the sake of interpretability is often portrayed as a tradeoff with model accuracy. You may find figures look like the above but replacing flexibility with accuracy. The basis for this argument is the assumption that more complex models have higher accuracy than simpler ones. Yet, this assumption is not always true. In many modelling contexts, interpretable models can be designed to achieve the same or comparable levels of accuracy as models that would be considered uninterpretable. Significant research efforts are underway to advance the field of <em>interpretable machine learning</em>. Over time, these research efforts can be expected to further reduce the range of contexts in which interpretability-accuracy tradeoffs are perceived to exist.</p>
<p>Decisions in favour of interpretability do not necessarily come at the expense of
accuracy. Where trade-offs between interpretability and accuracy do exist, it may be preferable
to accept a lower level of accuracy in the interest of enabling direct interpretation by system
developers and other relevant actors. Conversely, where uninterpretable models are being used,
it is important to be mindful of the limitations of explainability methods. Ignoring these limitations
risks having a false sense of understanding, potentially resulting in misplaced trust in ML systems
and unexpected harmful outcomes. Governance arrangements play a key role when it comes to
choosing appropriate types of models.</p>
</div>
<div class="section" id="communicating-system-logic-information">
<h4><span class="section-number">1.6.3.3. </span>Communicating system logic information<a class="headerlink" href="#communicating-system-logic-information" title="Permalink to this headline">¶</a></h4>
<p>System logic information is only useful if it is communicated to stakeholders in ways that are
intelligible and meaningful.</p>
<p>Stakeholders differ in their familiarity with technical concepts. Depending on the audience, system logic information may need to be translated from technical into plain language to make it intelligible. The form and degree of translation required can vary between audiences. For example, while customers may seek information that is presented in non-technical language, senior managers may be more comfortable with technical terms. Non-textual forms of presenting system logic information, including visuals or interactive dashboards, can also enhance intelligibility. Whether information is meaningful depends on the questions that stakeholders seek to answer. Questions can differ significantly between stakeholders, as can the level of detail expected in the answer to each question.</p>
<p>This can be particularly relevant when comparing the transparency interests of customers with
those involved in managing or monitoring the performance of ML systems. Three considerations
are worth highlighting:</p>
<ul class="simple">
<li><p><strong>The role of counterfactuals</strong>: The interest of customers in accessing system logic information can often be driven by questions about the conditions under which a system would yield a certain output (eg a favourable decision outcome). Such counterfactual explanations differ from the types of information that are of interest to other stakeholders, eg those who want to understand system performance.</p></li>
<li><p><strong>Relevance</strong>: Excessively detailed information or information that is irrelevant to customers’ queries can cause confusion and generate distrust.</p></li>
<li><p><strong>Intuitiveness and simplicity</strong>: Customers may expect the logic of systems to be sufficiently intuitive and simple, so that they are able to remember it in day-to-day life and make informed choices about aspects of their behaviour that may affect decision outcomes. Intelligibility alone does not guarantee that these expectations are met.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="process-transparency">
<h2><span class="section-number">1.7. </span>Process transparency<a class="headerlink" href="#process-transparency" title="Permalink to this headline">¶</a></h2>
<p>Now let us consider process transparency. We aim to answer three questions:</p>
<ul class="simple">
<li><p>What information falls under the category of process transparency.</p></li>
<li><p>Why stakeholders can be interested in such information.</p></li>
<li><p>How such information can be managed and communicated.</p></li>
</ul>
<p><a class="reference internal" href="#fig10-ai-transparency"><span class="std std-numref">Fig. 1.7</span></a> summarises process transparency in the three key questions above.</p>
<div class="figure align-default" id="fig10-ai-transparency">
<img alt="_images/fig10-ai-transparency.png" src="_images/fig10-ai-transparency.png" />
<p class="caption"><span class="caption-number">Fig. 1.7 </span><span class="caption-text">The what, why, and how of process transparency <span id="id8">[<a class="reference internal" href="index.html#id7" title="Florian Ostmann and Cosmina Dorobantu. AI in financial services. Alan Turing Institute. doi, 2021. https://www.turing.ac.uk/sites/default/files/2021-06/ati_ai_in_financial_services_lores.pdf.">Ostmann and Dorobantu, 2021</a>]</span> (maybe redraw later).</span><a class="headerlink" href="#fig10-ai-transparency" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="id9">
<h3><span class="section-number">1.7.1. </span>What relevant information?<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>Process transparency concerns access to any information about an ML system’s design, development,
and deployment apart from the system’s logic. As with system logic information, such process
information is important for addressing and providing assurance about concerns raised by AI
systems. Correspondingly, there is a growing amount of work on how process information can
be recorded, managed, and made accessible in practice.</p>
<p>We can categorise process information regarding ML systems along two dimensions:</p>
<ul class="simple">
<li><p><strong>Different lifecycle phases</strong>: Process information can relate to (i) the design and development or (ii) the deployment of an ML system. In both areas, more specific lifecycle phases can be distinguished, each of them associated with unique aspects of information.</p></li>
<li><p><strong>Different levels of information</strong>: In considering a given lifecycle phase, different levels of process information can be distinguished, corresponding to the kinds of questions that the information serves to answer.</p></li>
</ul>
<p>These two dimensions lead to a typology for process information whose general structure can be
represented in the form of a matrix, as illustrated in <a class="reference internal" href="#fig11-ai-transparency"><span class="std std-numref">Fig. 1.8</span></a>.</p>
<div class="figure align-default" id="fig11-ai-transparency">
<img alt="_images/fig11-ai-transparency.png" src="_images/fig11-ai-transparency.png" />
<p class="caption"><span class="caption-number">Fig. 1.8 </span><span class="caption-text">Process transparency matrix <span id="id10">[<a class="reference internal" href="index.html#id7" title="Florian Ostmann and Cosmina Dorobantu. AI in financial services. Alan Turing Institute. doi, 2021. https://www.turing.ac.uk/sites/default/files/2021-06/ati_ai_in_financial_services_lores.pdf.">Ostmann and Dorobantu, 2021</a>]</span> (maybe redraw later).</span><a class="headerlink" href="#fig11-ai-transparency" title="Permalink to this image">¶</a></p>
</div>
<p>Let us study the different levels of information below. For each lifecycle phase of an ML system, there are various aspects of information that can be of interest to internal or external stakeholders. These aspects of information can answer questions at different levels of abstraction. The following four levels of information can be distinguished, moving from more concrete to more abstract questions:</p>
<ul class="simple">
<li><p><strong>Substantive information</strong> relates to questions about substantive aspects of activities within a given lifecycle phase for an ML system. Examples of such information include: the content of problem definition or system requirement statements; the content of or summary statistics for datasets used during the ML system’s development and operation; source code or other formal representations of the ML system; and the results of tests conducted to assess system performance or compliance.</p></li>
<li><p><strong>Procedural information</strong> answers questions about the procedures that were followed in performing the activities within a given lifecycle phase. Examples include descriptions of: the process that led to the agreed problem definition or system requirements (eg the actors and the steps involved); the procedures employed to collect and assemble the data used during the ML system’s development or operation; the nature of data quality checks or processing steps carried out; the process followed to select the type of ML method used for developing models; or the procedures used to conduct system tests.</p></li>
<li><p><strong>Governance information</strong> answers questions about governance arrangements for activities conducted within a lifecycle phase. This information may take the form of statements of accountability and liability, or descriptions of the structure of relevant oversight mechanisms (including, where relevant, the role of risk and compliance teams, ethics review boards, audit teams, senior managers, or board members).</p></li>
<li><p><strong>Information on adherence to norms and standards</strong> refers to compliance with norms or standards in the design, development, and deployment of an ML system. Such norms or standards may touch on substantive, procedural, or governance questions.</p></li>
</ul>
<p>The distinction between these four levels of information remains unaffected by the complexities of sourcing data for ML systems or technology supply chains. Where firms rely on third-party providers, all four levels of information can be applied to activities carried out within and outside the firm. Additionally, relevant governance information in such cases can include information about accountability structures and mechanisms that govern the relationship between third-party providers and the firm employing the ML system in question. These four levels of information, combined with the typology of lifecycle phases, lead to a more concrete version of the matrix we introduced at the beginning of this section to map out different types of process information.</p>
<p><a class="reference internal" href="#fig12-ai-transparency"><span class="std std-numref">Fig. 1.9</span></a> incorporates specific categories into <a class="reference internal" href="#fig11-ai-transparency"><span class="std std-numref">Fig. 1.8</span></a>.</p>
<div class="figure align-default" id="fig12-ai-transparency">
<img alt="_images/fig12-ai-transparency.png" src="_images/fig12-ai-transparency.png" />
<p class="caption"><span class="caption-number">Fig. 1.9 </span><span class="caption-text">Detailed process transparency matrix <span id="id11">[<a class="reference internal" href="index.html#id7" title="Florian Ostmann and Cosmina Dorobantu. AI in financial services. Alan Turing Institute. doi, 2021. https://www.turing.ac.uk/sites/default/files/2021-06/ati_ai_in_financial_services_lores.pdf.">Ostmann and Dorobantu, 2021</a>]</span> (maybe redraw later).</span><a class="headerlink" href="#fig12-ai-transparency" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="id12">
<h3><span class="section-number">1.7.2. </span>Why such info?<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p>Process information, like system logic information, can help to address concerns related to AI
systems (ensuring the trustworthiness and responsible use of these systems) as well as to provide
assurance that concerns have been addressed adequately (demonstrating trustworthiness and
responsible use). In the following paragraphs, we illustrate the importance of process transparency
in addressing each of the six areas of concern as in <a class="reference internal" href="#fig9-ai-transparency"><span class="std std-numref">Fig. 1.5</span></a>.</p>
<ul class="simple">
<li><p><strong>System performance</strong>: Information about the content of system requirement specifications, about the quality and origin of data used during an ML system’s development or operation, or about validation procedures is crucial for understanding the effectiveness, reliability, and robustness of ML systems. This information can be of interest to those involved in or making decisions about the development and use of an ML system, as well as those seeking assurance about the system’sm performance (eg members of audit teams, board members, regulators or customers).</p></li>
<li><p><strong>System compliance</strong>: Process information is crucial to assessing ML systems’ adherence to compliance requirements. For example, information about the quality of data used and system tests conducted is essential for a holistic understanding of potential risks of unlawful discrimination. Similarly, where ML systems use personal data, information about the provenance, content, and quality of this data is important for data protection assessments. Process information can be of interest to those ensuring system compliance or can demonstrate system compliance to stakeholders.</p></li>
<li><p><strong>Competent use and human oversight</strong>: Information about an ML system’s intended purpose, system requirements specifications, or system performance measurements can be essential to ensuring competent use and preventing the inappropriate repurposing of ML systems. This information can also be crucial to determine what forms of human oversight are needed and to enable overseers to exercise their role effectively.</p></li>
<li><p><strong>Providing explanations</strong>: Explanations of an ML system’s outputs can involve system logic information as well as process information. Indeed, a complete understanding of a particular decision requires both. <a class="reference internal" href="#fig13-ai-transparency"><span class="std std-numref">Fig. 1.10</span></a> illustrates this using the example of a loan eligibility decision. In terms of process information, decision recipients seeking to understand an outcome may want to know the content of the input data about them that an ML system used. This knowledge is a precondition, for example, for being able to identify erroneous decisions.</p></li>
</ul>
<div class="figure align-default" id="fig13-ai-transparency">
<img alt="_images/fig13-ai-transparency.png" src="_images/fig13-ai-transparency.png" />
<p class="caption"><span class="caption-number">Fig. 1.10 </span><span class="caption-text">The combined relevance of process and system logic information in explaining system outputs <span id="id13">[<a class="reference internal" href="index.html#id7" title="Florian Ostmann and Cosmina Dorobantu. AI in financial services. Alan Turing Institute. doi, 2021. https://www.turing.ac.uk/sites/default/files/2021-06/ati_ai_in_financial_services_lores.pdf.">Ostmann and Dorobantu, 2021</a>]</span> (maybe redraw later).</span><a class="headerlink" href="#fig13-ai-transparency" title="Permalink to this image">¶</a></p>
</div>
<ul class="simple">
<li><p><strong>Responsiveness</strong>: Telling users about ways in which they can ask for information, help, or redress is important to reassure them of the existence of pathways for expressing such requests. In addition, internal stakeholders may need access to different forms of process information, such as the data used during an ML system’s operation, to be able to respond to customer requests. Finally, stakeholders seeking assurance about the responsible use of ML systems may be interested in information about how issues of responsiveness are managed.</p></li>
<li><p><strong>Social and economic impact</strong>: Various types of process information may be needed to manage and provide assurance regarding the social and economic impacts of an ML system. For example, information about system test results can be important for understanding an ML system’s potential financial exclusion implications. Similarly, information about how firms communicate personal data use to customers can be of interest to stakeholders seeking assurance in relation to concerns regarding consumer empowerment.</p></li>
</ul>
</div>
<div class="section" id="how-to-manage-such-info">
<h3><span class="section-number">1.7.3. </span>How to manage such info?<a class="headerlink" href="#how-to-manage-such-info" title="Permalink to this headline">¶</a></h3>
<p>The appropriate level of detail and technical sophistication in providing process information will depend on the purpose that the information is meant to serve. For example, actors involved directly in the validation of an ML system are likely to need a system requirements statement. Customers or other stakeholders interested in ensuring that the right procedures have been followed in validating an ML system will likely need less detailed information, expressed in easy-to-understand language.</p>
<p>Existing best practices within firms – even if they are not specifically designed for ML systems – can guide the process of identifying suitable ways of recording and presenting process information. We consider three areas of research and development related to managing and communicating process information below.</p>
<p><strong>Recording and presenting process information for ML systems</strong>: Recent years have seen a rapidly growing literature on topics such as documentation, assurance, traceability, and audit trails for ML systems. Contributions to this literature often give examples of how different aspects of process information can be recorded and made accessible to different stakeholders. In many cases, these examples involve proposals for different ‘documentation artefacts’ and templates that can be used to structure process information in practice.</p>
<p>Some contributions to this debate are focused on subsets of process information or the information needs of particular stakeholders. Increasingly, however, contributions adopt a holistic perspective on documentation needs, covering all phases of an ML system’s lifecycle as well as the information needs of all relevant stakeholders. An approach that is growing in popularity – especially in the context of high-stakes applications of ML/AI – is the use of ‘argument-based assurance cases’, often following a specified template, in support of claims about an ML system’s properties.</p>
<p>Recent years have also seen an increase in the number of open-source tools for testing ML systems and examining their properties. These tools can be useful for generating some of the process information that is of interest to stakeholders.</p>
<p><strong>Emerging norms and standards</strong>: A second evolving area with relevance to managing and communicating process information consists of work on standards for ML systems and on professional standards. Several national and international bodies are currently working to develop standards for ML systems. These standards serve as a useful point of reference though their applicability to real-world use cases will depend on context.</p>
<p>In addition, recent years have seen growing support of initiatives to professionalise the field of data science. Efforts in this space are aimed at establishing commonly agreed curricula for data science courses and possible forms of professional accreditation for data scientists. For example, a group of professional bodies led by the Royal Statistical Society (RSS) is currently working to develop commonly agreed professional standards for data science.Concurrently, some professional bodies in the financial services space are turning their attention to codes of conduct for the use of data and emerging technologies.</p>
<p><strong>Mechanisms for verifying process information</strong>: A third area of emerging work concerns the verifiability of process information for ML systems. This includes forms of independent certification for relevant norms and standards. Currently, declarations of adherence to norms and standards take the form of self-declared adherence (‘self-certification’). However, in some contexts, stakeholders may place greater trust in such declarations if they are supported by independently administered certification or labelling schemes.</p>
<p>There is also an emerging literature on the role of auditors in examining system design, development, and deployment processes (including evaluation). In contrast to certification, auditors may verify process information at a more detailed level. ML system auditors can be internal or external to the firm that is employing a given ML system.</p>
<p>Finally, growing research and development efforts are being dedicated to technical solutions that automate the generation and recording of process information. Software-generated ‘audit trails’ and related concepts can contribute to the reliability and verifiability of some types of process information, while at the same time reducing the cost of recording and making the information available to stakeholders.</p>
</div>
</div>
<div class="section" id="k-nearest-neighbors-knn-classification">
<h2><span class="section-number">1.8. </span>K-Nearest Neighbors (KNN) classification<a class="headerlink" href="#k-nearest-neighbors-knn-classification" title="Permalink to this headline">¶</a></h2>
<p>We adapt the <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py">KNN example from scikit-learn</a> to illustrate the use of KNN for classification.</p>
<div class="section" id="id14">
<h3><span class="section-number">1.8.1. </span>Exercises<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<p>min 3 max 5</p>
</div>
</div>
<div class="section" id="quiz">
<h2><span class="section-number">1.9. </span>Quiz<a class="headerlink" href="#quiz" title="Permalink to this headline">¶</a></h2>
<p><em>Not for now. To finish in the next cycle.</em> Complete <a class="reference external" href="https://forms.gle/8Q5Z7Z7Z7Z7Z7Z7Z7">Quiz</a> to check your understanding of this topic. You are advised to score at least 50% to proceed to the next topic.</p>
</div>
<div class="section" id="summary">
<h2><span class="section-number">1.10. </span>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>Machine learning automates the process of learning a model from data that captures hidden patterns or relationship to help us make intelligent, data-driven predictions or decisions. It has been proven to be very useful in many applications, such as image recognition, speech recognition, natural language processing, and many more. Understanding and applying machine learning through this course will help you to acquire essential skills for solving many real-world problems.</p>
<p>In this topic, you learned:</p>
<ul class="simple">
<li><p>Machine learning learns a model from data to make predictions or decisions.</p></li>
<li></li>
</ul>
</div>
<div class="section" id="references-and-further-reading">
<h2><span class="section-number">1.11. </span>References and further reading<a class="headerlink" href="#references-and-further-reading" title="Permalink to this headline">¶</a></h2>
<p>This material is based on the following resources:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/microsoft/ML-For-Beginners">Machine Learning for Beginners - A Curriculum</a>, Microsoft</p></li>
<li><p><a class="reference external" href="https://dmol.pub/">Deep Learning for Molecules &amp; Materials</a></p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="00-prerequisites.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Prerequisites</p>
        </div>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Haiping Lu and Shuo Zhou<br/>
    
        &copy; Copyright 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>